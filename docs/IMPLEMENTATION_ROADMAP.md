# ðŸ“‹ Implementation Roadmap: World-Class Gravity Model Platform

**Status:** In Progress - Sprint 1
**Last Updated:** 2026-01-14
**Owner:** Dr. Ian Helfrich

---

## ðŸŽ¯ Vision

Transform the current proof-of-concept (3 years, top 20 countries, single model) into a **world-class interactive research platform** for gravity model analysis that serves:

- **Graduate students** learning international trade economics
- **Researchers** conducting cutting-edge gravity model research
- **Policymakers** analyzing trade agreements and shocks
- **Business strategists** evaluating market entry and supply chain decisions

---

## ðŸ“Š Current State vs. Target State

| Dimension | Current | Target | Status |
|-----------|---------|--------|--------|
| **Years** | 3 (2019-2021) | 24+ (2000-2023) | ðŸŸ¡ In Progress |
| **Countries** | Top 20 Ã— 20 | All available (~200) | ðŸŸ¡ In Progress |
| **Observations** | 1,200 | ~1,000,000 | ðŸŸ¡ In Progress |
| **Sectors** | Aggregate only | HS2 (97) + HS4 (1,200+) | ðŸ”´ Not Started |
| **Models** | 1 (AvW 2003) | 4+ (AvW, H-M, Yotov, IV) | ðŸ”´ Not Started |
| **Counterfactuals** | Partial Equilibrium | General Equilibrium | ðŸ”´ Not Started |
| **Deployment** | Static GitHub Pages | Dynamic API + Frontend | ðŸ”´ Not Started |
| **Performance** | <1s load (434KB) | <2s load (any query) | ðŸŸ¢ Currently Excellent |

---

## ðŸš€ Sprint Plan (6 Weeks)

### Sprint 1: Data Foundation (Week 1) - **IN PROGRESS**

**Goal:** Expand from 1,200 to 1M+ observations

**Tasks:**
- [x] Create `EXPANSION_PLAN.md` with comprehensive vision
- [x] Create `IMPLEMENTATION_ROADMAP.md` for tracking
- [x] Write `scripts/05_build_full_dataset.py` for data extraction
- [ ] Test script on full BACI data (all years, all countries)
- [ ] Analyze data size and performance implications
- [ ] Document year coverage and country availability
- [ ] Create data quality report

**Deliverables:**
- âœ… `docs/EXPANSION_PLAN.md` - Vision document
- âœ… `scripts/05_build_full_dataset.py` - Data extraction script
- â³ `data/processed/baci_gravity_full.parquet` - Full dataset (~200MB estimated)
- â³ `outputs/tables/data_quality_report.csv` - Coverage by year/country

**Success Criteria:**
- Can extract 500,000+ observations (2010-2023)
- Processing time < 5 minutes on standard laptop
- File size < 300MB compressed
- Zero merge errors or data quality issues

---

### Sprint 2: Backend API (Week 2)

**Goal:** Enable dynamic filtering without loading entire dataset in browser

**Architecture:**
```
User Browser â†’ FastAPI Server â†’ DuckDB â†’ Parquet Files
     â†“              â†“              â†“
  Three.js â† JSON Response â† SQL Query
```

**Tasks:**
- [ ] Set up FastAPI project structure
- [ ] Implement DuckDB query layer
- [ ] Create REST endpoints:
  - `GET /api/data?year=2020&origin=USA&dest=CHN`
  - `GET /api/countries` - List available countries
  - `GET /api/years` - List available years
  - `GET /api/sectors` - List available HS2 sectors
  - `POST /api/estimate` - Run PPML estimation
  - `POST /api/counterfactual` - Compute GE counterfactual
- [ ] Add caching layer (Redis or simple in-memory)
- [ ] Deploy to Railway.app or Render.com
- [ ] Load testing (100+ concurrent users)

**Deliverables:**
- `backend/` directory with FastAPI app
- `backend/requirements.txt` - Python dependencies
- `backend/Dockerfile` - Containerized deployment
- API documentation (auto-generated by FastAPI)
- Deployed API endpoint (e.g., `https://gravity-api.railway.app`)

**Success Criteria:**
- API responds in < 500ms for typical queries
- Can handle 100 concurrent requests
- 99.9% uptime over 7-day period
- Complete API documentation with examples

---

### Sprint 3: Model Variants (Week 3)

**Goal:** Allow users to compare different gravity specifications

**Models to Implement:**

#### Model A: Anderson-van Wincoop (2003) âœ… **DONE**
```python
formula = "trade ~ ln_dist + contig + comlang_off + comcol + rta + C(year) + C(iso_o) + C(iso_d)"
model = GLM(formula, data=df, family=Poisson())
```

#### Model B: Head-Mayer (2014) Toolkit
```python
formula = "trade ~ ln_dist + contig + comlang_off + comcol + rta + C(year_iso_o) + C(year_iso_d)"
# Exporter-year and importer-year FE
```

#### Model C: Yotov et al. (2016) Structural
```python
formula = "trade ~ C(year_iso_o) + C(year_iso_d) + C(pair) + border + rta"
# Pair FE controls for all time-invariant bilateral characteristics
```

#### Model D: Instrumental Variables (2SLS)
```python
# IV for RTA endogeneity
instruments = ['neighbor_rta_count', 'colonial_bloc']
iv_model = IV2SLS(y, X, Z, instruments)
```

**Tasks:**
- [ ] Implement each model specification
- [ ] Create model comparison table
- [ ] Add model selector dropdown to UI
- [ ] Compute standard errors (clustered by dyad, year, both)
- [ ] Implement diagnostic tests (reset, heteroskedasticity)

**Deliverables:**
- `src/models/gravity_models.py` - Model implementations
- `src/models/model_comparison.py` - Comparison utilities
- Updated web UI with model selector
- `outputs/tables/model_comparison.tex` - LaTeX table

**Success Criteria:**
- All 4 models estimate successfully
- Coefficient differences documented and explained
- Elasticity estimates within expected ranges from literature
- Standard errors correctly computed

---

### Sprint 4: Sector-Level Analysis (Week 4)

**Goal:** Enable product-level gravity estimation

**Data Sources:**
- `bilateral_sector_flows.parquet` - HS2 trade (97 sectors)
- `hs_by_dyad/` directory - HS4 detailed flows (~1,200 products)
- `product_codes_hs02.parquet` - Sector descriptions

**Tasks:**
- [ ] Create `scripts/06_build_sector_data.py`
- [ ] Extract HS2 flows merged with gravity
- [ ] Estimate sector-specific gravity models
- [ ] Compute heterogeneous elasticities by sector
- [ ] Add sector dropdown to UI
- [ ] Create sector comparison visualizations

**Examples:**
- "Distance elasticity for automobiles vs. textiles"
- "RTA effects on agricultural trade"
- "Contiguity matters more for heavy/bulky goods"

**Deliverables:**
- Sector-level dataset (~100M observations for HS4)
- Sector-specific coefficient estimates
- UI with sector filter and comparison
- `outputs/figures/sector_elasticities.png` - Heterogeneity plot

**Success Criteria:**
- 97 HS2 sectors available
- Distance elasticity varies sensibly (higher for heavy goods)
- UI loads sector data in < 2s

---

### Sprint 5: General Equilibrium Counterfactuals (Week 5)

**Goal:** Implement full GE effects following Larch & Yotov (2016)

**Algorithm (Ge-PPML):**

```python
def solve_ge_counterfactual(X_baseline, tau_shock, max_iter=100, tol=1e-6):
    """
    Solve for new equilibrium prices/wages after trade cost shock.

    Parameters:
    -----------
    X_baseline : array
        Baseline trade flows (N x N matrix)
    tau_shock : array
        Trade cost multipliers (N x N matrix, e.g., 1.1 = 10% tariff increase)
    max_iter : int
        Maximum iterations for convergence
    tol : float
        Convergence tolerance

    Returns:
    --------
    dict with:
        - X_counterfactual: New trade flows
        - welfare_changes: Real wage changes by country
        - terms_of_trade: ToT effects
        - iteration_count: Iterations to converge
    """
    # Step 1: Compute baseline multilateral resistances
    P_i, Pi_j = compute_multilateral_resistance(X_baseline)

    # Step 2: Apply shock to trade costs
    tau_cf = tau_baseline * tau_shock

    # Step 3: Iterate until convergence
    for iter in range(max_iter):
        # Update trade flows
        X_new = update_trade_flows(X_cf, P_i, Pi_j, tau_cf)

        # Check market clearing
        if check_convergence(X_new, X_cf, tol):
            break

        # Update multilateral resistances
        P_i, Pi_j = compute_multilateral_resistance(X_new)
        X_cf = X_new

    # Step 4: Compute welfare effects
    welfare = compute_welfare_changes(P_i, Pi_j, P_i_baseline, Pi_j_baseline)

    return {
        'X_counterfactual': X_cf,
        'welfare_changes': welfare,
        'terms_of_trade': compute_tot(X_cf, X_baseline),
        'iteration_count': iter
    }
```

**Tasks:**
- [ ] Implement Ge-PPML solver
- [ ] Add welfare decomposition (ToT, variety, volume)
- [ ] Create GE vs. PE comparison visualizations
- [ ] Add "Run GE Counterfactual" button to UI (with loading spinner)
- [ ] Document limitations and assumptions

**Deliverables:**
- `src/models/ge_solver.py` - GE counterfactual engine
- `src/models/welfare.py` - Welfare calculation utilities
- Updated UI with GE toggle
- `outputs/figures/ge_vs_pe_comparison.png`

**Success Criteria:**
- GE solver converges in < 50 iterations
- Welfare changes sum to zero (general equilibrium property)
- Results match Yotov et al. (2016) benchmark examples
- Processing time < 30s for 200 countries

---

### Sprint 6: Polish & Deploy (Week 6)

**Goal:** Production-ready platform with world-class UX

**Tasks:**

#### Performance Optimization
- [ ] Implement lazy loading for large datasets
- [ ] Add Web Workers for heavy computations
- [ ] Optimize Three.js rendering (LOD, frustum culling)
- [ ] CDN for static assets (Cloudflare)
- [ ] Gzip compression for API responses

#### User Experience
- [ ] Mobile-responsive design (test on iOS/Android)
- [ ] Accessibility audit (WCAG 2.1 AA compliance)
- [ ] Add loading states and progress bars
- [ ] Improve error messages (user-friendly)
- [ ] Add tooltips and help popovers
- [ ] Create video tutorial (3-5 minutes)

#### Documentation
- [ ] Update README with full feature list
- [ ] Create user guide (`docs/USER_GUIDE.md`)
- [ ] API documentation with Swagger UI
- [ ] Add FAQ page
- [ ] Create Jupyter notebook tutorials

#### Analytics & Monitoring
- [ ] Google Analytics 4 integration
- [ ] Error tracking (Sentry.io)
- [ ] Performance monitoring (web vitals)
- [ ] User feedback form

#### SEO & Discoverability
- [ ] Meta tags for social sharing
- [ ] Open Graph images
- [ ] Sitemap.xml
- [ ] Submit to Google Scholar
- [ ] Share on Twitter, LinkedIn, ResearchGate

**Deliverables:**
- Performance report (Lighthouse score >90)
- Accessibility audit report
- User guide and tutorials
- Marketing materials (blog post, demo video)
- Monitoring dashboard

**Success Criteria:**
- Lighthouse score >90 (all categories)
- <2s load time (95th percentile)
- Zero critical accessibility issues
- 100+ users in first week
- 10+ citations/mentions within 3 months

---

## ðŸ“¦ Technical Stack

### Current Stack âœ…
- **Frontend:** Three.js r169, vanilla JavaScript
- **Hosting:** GitHub Pages (static)
- **Data:** Parquet â†’ JSON (434KB)
- **Estimation:** Python statsmodels (PPML)

### Additions Needed

**Backend (Sprint 2):**
- **Framework:** FastAPI 0.109+
- **Database:** DuckDB 0.9+ (in-process OLAP)
- **Deployment:** Railway.app or Render.com
- **Caching:** Redis or in-memory LRU

**Frontend Enhancements (Sprint 6):**
- **Charts:** Plotly.js (time series, comparisons)
- **UI Components:** Shoelace web components
- **State:** Lightweight state management (Zustand)
- **Build:** Vite (for faster development)

**Data Processing (Sprint 1, 4, 5):**
- **ETL:** Pandas 2.0+, PyArrow 14+
- **Econometrics:** statsmodels, linearmodels, scipy
- **GE Solver:** Custom NumPy implementation

---

## ðŸŽ“ Use Cases & Examples

### Use Case 1: Policy Analysis - Brexit Impact
**Scenario:** UK leaves EU customs union (2020)
**Data:** 2015-2023 UK-EU trade flows
**Model:** Yotov structural with pair FE
**Counterfactual:** Remove UK-EU RTA, add border costs
**Output:**
- Trade volume changes by partner
- UK welfare loss estimate
- Sector-specific impacts (services vs. goods)

### Use Case 2: Research - Distance Puzzle
**Scenario:** Has globalization reduced distance elasticity?
**Data:** 2000-2023 all countries
**Model:** AvW with interaction terms (year Ã— distance)
**Analysis:** Test if Î¸ (distance elasticity) has declined over time
**Output:**
- Time-varying elasticity plot
- Structural break tests
- Comparison to literature estimates

### Use Case 3: Education - Teaching Gravity Models
**Scenario:** Graduate trade course lab assignment
**Data:** Instructor-selected sample
**Model:** Students compare all 4 specifications
**Activity:**
- Estimate models
- Interpret coefficients
- Run counterfactuals
- Write policy brief

---

## ðŸ“ˆ Success Metrics

### Short-term (3 months)
- [ ] 1,000+ unique visitors
- [ ] 500+ counterfactuals run
- [ ] 10+ GitHub stars
- [ ] 5+ mentions on Twitter/LinkedIn
- [ ] 2+ professors use in courses

### Medium-term (12 months)
- [ ] 10,000+ unique visitors
- [ ] 5,000+ counterfactuals run
- [ ] 50+ GitHub stars
- [ ] 10+ academic citations
- [ ] Featured in 1+ academic journal (Data in Brief, etc.)
- [ ] 10+ universities using in courses

### Long-term (3 years)
- [ ] 50,000+ unique visitors
- [ ] 50+ academic citations
- [ ] Mentioned in policy reports (WTO, IMF, World Bank)
- [ ] Integration with WITS, COMTRADE, or CEPII platforms
- [ ] Funding for continued development (NSF grant, foundation)

---

## ðŸš§ Risks & Mitigation

| Risk | Impact | Likelihood | Mitigation |
|------|--------|-----------|------------|
| Data too large for browser | High | Medium | Backend API with filtering (Sprint 2) |
| GE solver doesn't converge | High | Medium | Fallback to PE, add solver diagnostics |
| Slow estimation (large datasets) | Medium | High | Pre-compute results, cache common queries |
| Hosting costs too high | Medium | Low | Use free tier (Railway), optimize caching |
| Low user adoption | Medium | Medium | Marketing, SEO, academic outreach |
| Code maintenance burden | Low | High | Good documentation, modular design |

---

## ðŸ‘¥ Team & Resources

**Current Team:**
- Dr. Ian Helfrich (Lead Developer)

**Needed Resources:**
- Cloud hosting budget: $0-50/month (Railway free tier â†’ paid)
- Domain name: $12/year (optional)
- CDN: Cloudflare free tier
- Monitoring: Sentry.io free tier
- Time commitment: 20 hours/week Ã— 6 weeks = 120 hours

**Potential Collaborators:**
- Graduate students (RA positions)
- Open-source contributors (GitHub)
- Trade economists (feedback, validation)
- Web developers (UI/UX improvements)

---

## ðŸ“ž Communication Plan

**Weekly Updates:**
- Sprint status (tasks completed, in progress, blocked)
- Performance metrics (users, errors, feedback)
- Next week priorities

**Milestones:**
- Sprint 1 complete â†’ Blog post on data expansion
- Sprint 3 complete â†’ Paper: "Comparing Gravity Model Specifications"
- Sprint 5 complete â†’ Workshop: "GE Counterfactuals in Practice"
- Sprint 6 complete â†’ Launch announcement (Twitter, LinkedIn, ResearchGate)

---

## ðŸ“š References & Resources

**Gravity Model Literature:**
- Anderson & van Wincoop (2003) - Foundational structural gravity
- Santos Silva & Tenreyro (2006) - PPML estimation
- Head & Mayer (2014) - Gravity toolkit
- Yotov et al. (2016) - Advanced guide (UN/WTO)
- Larch & Yotov (2016) - Ge-PPML methodology

**Data Sources:**
- BACI (CEPII) - Bilateral trade flows
- Gravity Dataset v202211 (CEPII) - Bilateral variables
- WITS (World Bank) - Alternative trade data
- COMTRADE (UN) - Detailed commodity data

**Technical Resources:**
- Three.js documentation
- FastAPI tutorial
- DuckDB documentation
- PPML estimation in Python (GitHub examples)

---

**Document Status:** Living Document
**Review Frequency:** After each sprint
**Next Review:** Sprint 1 completion (est. 2026-01-20)
